"""
Meta-Learner Agent: Autonomous System Improvement Engine

This is the core innovation of Agent 06 - a meta-learning system that:
- Learns from system performance and user interactions
- Adapts strategies based on observed outcomes
- Generates insights and optimization recommendations
- Implements self-improving algorithms
- Evolves system behavior through experience

The meta-learner continuously analyzes system behavior, identifies patterns,
and implements improvements to enhance overall system performance.
"""

import asyncio
import logging
import time
import json
import hashlib
from typing import Dict, Any, Optional, List, Tuple, Set
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
import statistics
import random

from app.core.base_agent import BaseAgent, AgentCapability
from app.core.message_bus import get_message_bus
from app.models.messaging import (
    TaskEnvelope, TaskResultEnvelope, AgentEventEnvelope, MetricEnvelope,
    create_task_result_envelope, create_metric_envelope
)

logger = logging.getLogger(__name__)


class LearningMode(Enum):
    """Meta-learning operational modes."""
    OBSERVATION = "observation"      # Learning from system behavior
    EXPERIMENTATION = "experimentation"  # Testing new strategies
    OPTIMIZATION = "optimization"    # Implementing improvements
    ADAPTATION = "adaptation"        # Adjusting to changing conditions


class InsightType(Enum):
    """Types of insights the meta-learner can generate."""
    PERFORMANCE_PATTERN = "performance_pattern"
    EFFICIENCY_IMPROVEMENT = "efficiency_improvement"
    ERROR_PATTERN = "error_pattern"
    RESOURCE_OPTIMIZATION = "resource_optimization"
    STRATEGY_IMPROVEMENT = "strategy_improvement"
    PREDICTIVE_INSIGHT = "predictive_insight"


@dataclass
class LearningExperience:
    """A single learning experience for the meta-learner."""
    experience_id: str
    timestamp: datetime
    context: Dict[str, Any]
    action_taken: str
    outcome: Dict[str, Any]
    performance_metrics: Dict[str, Any]
    lessons_learned: List[str] = field(default_factory=list)
    confidence_score: float = 0.5
    impact_score: float = 0.0


@dataclass
class StrategyPattern:
    """A learned strategy pattern."""
    pattern_id: str
    description: str
    conditions: Dict[str, Any]
    actions: List[str]
    expected_outcome: Dict[str, Any]
    success_rate: float = 0.0
    usage_count: int = 0
    last_used: Optional[datetime] = None
    confidence_level: float = 0.5


@dataclass
class SystemInsight:
    """An insight generated by the meta-learner."""
    insight_id: str
    insight_type: InsightType
    description: str
    evidence: List[Dict[str, Any]]
    recommendation: str
    confidence_score: float
    impact_potential: float
    implementation_complexity: str
    generated_at: datetime
    applied: bool = False
    applied_at: Optional[datetime] = None
    results: Optional[Dict[str, Any]] = None


class ExperienceMemory:
    """Memory system for storing and retrieving learning experiences."""

    def __init__(self, max_experiences: int = 10000):
        self.experiences: List[LearningExperience] = []
        self.max_experiences = max_experiences
        self.patterns: Dict[str, StrategyPattern] = {}

    def add_experience(self, experience: LearningExperience) -> None:
        """Add a new learning experience."""
        self.experiences.append(experience)

        # Maintain memory limit
        if len(self.experiences) > self.max_experiences:
            # Remove oldest experiences (keep most recent)
            self.experiences = self.experiences[-self.max_experiences:]

    def find_similar_experiences(self, context: Dict[str, Any],
                                limit: int = 5) -> List[LearningExperience]:
        """Find experiences similar to the given context."""
        similar_experiences = []

        for exp in self.experiences:
            similarity_score = self._calculate_similarity(exp.context, context)
            if similarity_score > 0.3:  # Similarity threshold
                similar_experiences.append((exp, similarity_score))

        # Sort by similarity and return top matches
        similar_experiences.sort(key=lambda x: x[1], reverse=True)
        return [exp for exp, score in similar_experiences[:limit]]

    def extract_patterns(self) -> List[StrategyPattern]:
        """Extract successful strategy patterns from experiences."""
        patterns = []

        # Group experiences by action and context patterns
        action_groups = {}
        for exp in self.experiences:
            action_key = exp.action_taken
            if action_key not in action_groups:
                action_groups[action_key] = []
            action_groups[action_key].append(exp)

        # Analyze each action group for patterns
        for action, experiences in action_groups.items():
            if len(experiences) < 3:  # Need minimum experiences for pattern
                continue

            # Calculate success rate
            successful_exps = [e for e in experiences if e.outcome.get('success', False)]
            success_rate = len(successful_exps) / len(experiences)

            if success_rate > 0.7:  # High success rate threshold
                # Extract common context patterns
                common_context = self._extract_common_context(experiences)

                pattern = StrategyPattern(
                    pattern_id=f"pattern_{hashlib.md5(action.encode()).hexdigest()[:8]}",
                    description=f"Successful strategy: {action}",
                    conditions=common_context,
                    actions=[action],
                    expected_outcome={'success': True, 'success_rate': success_rate},
                    success_rate=success_rate,
                    usage_count=len(experiences),
                    confidence_level=min(0.95, success_rate + 0.1)
                )

                patterns.append(pattern)

        return patterns

    def _calculate_similarity(self, context1: Dict[str, Any], context2: Dict[str, Any]) -> float:
        """Calculate similarity between two contexts."""
        if not context1 or not context2:
            return 0.0

        common_keys = set(context1.keys()) & set(context2.keys())
        if not common_keys:
            return 0.0

        similarity_scores = []
        for key in common_keys:
            val1, val2 = context1[key], context2[key]
            if val1 == val2:
                similarity_scores.append(1.0)
            elif isinstance(val1, (int, float)) and isinstance(val2, (int, float)):
                # Numeric similarity
                diff = abs(val1 - val2)
                max_val = max(abs(val1), abs(val2))
                if max_val > 0:
                    similarity_scores.append(1.0 - min(diff / max_val, 1.0))
                else:
                    similarity_scores.append(1.0 if val1 == val2 else 0.0)
            else:
                similarity_scores.append(0.0)  # Different types or values

        return sum(similarity_scores) / len(similarity_scores) if similarity_scores else 0.0

    def _extract_common_context(self, experiences: List[LearningExperience]) -> Dict[str, Any]:
        """Extract common context patterns from experiences."""
        if not experiences:
            return {}

        # Find most common values for each key
        context_keys = set()
        for exp in experiences:
            context_keys.update(exp.context.keys())

        common_context = {}
        for key in context_keys:
            values = [exp.context.get(key) for exp in experiences if key in exp.context]
            if values:
                # Use most common value
                most_common = max(set(values), key=values.count)
                common_context[key] = most_common

        return common_context


class InsightGenerator:
    """Generates insights from system behavior and learning experiences."""

    def __init__(self):
        self.generated_insights: List[SystemInsight] = []
        self.applied_insights: List[SystemInsight] = []

    def analyze_performance_patterns(self, experiences: List[LearningExperience]) -> List[SystemInsight]:
        """Analyze performance patterns to generate insights."""
        insights = []

        if len(experiences) < 5:
            return insights

        # Analyze performance trends
        recent_experiences = experiences[-20:]  # Last 20 experiences

        # Check for performance degradation
        performance_scores = [exp.performance_metrics.get('overall_score', 0) for exp in recent_experiences]
        if len(performance_scores) >= 5:
            recent_avg = statistics.mean(performance_scores[-5:])
            older_avg = statistics.mean(performance_scores[:-5]) if len(performance_scores) > 5 else recent_avg

            if recent_avg < older_avg * 0.9:  # 10% degradation
                insight = SystemInsight(
                    insight_id=f"perf_degradation_{int(time.time())}",
                    insight_type=InsightType.PERFORMANCE_PATTERN,
                    description="System performance degradation detected",
                    evidence=[
                        {"metric": "average_performance", "recent": recent_avg, "previous": older_avg},
                        {"trend": "declining", "magnitude": (older_avg - recent_avg) / older_avg}
                    ],
                    recommendation="Investigate recent changes and consider performance optimization",
                    confidence_score=0.8,
                    impact_potential=0.7,
                    implementation_complexity="medium",
                    generated_at=datetime.now()
                )
                insights.append(insight)

        # Check for resource optimization opportunities
        resource_usage = [exp.performance_metrics.get('resource_efficiency', 1.0) for exp in recent_experiences]
        if resource_usage and statistics.mean(resource_usage) < 0.7:  # Low efficiency
            insight = SystemInsight(
                insight_id=f"resource_opt_{int(time.time())}",
                insight_type=InsightType.RESOURCE_OPTIMIZATION,
                description="Resource utilization can be optimized",
                evidence=[
                    {"metric": "average_resource_efficiency", "value": statistics.mean(resource_usage)},
                    {"recommendation": "Implement resource pooling and caching strategies"}
                ],
                recommendation="Optimize resource allocation and implement caching strategies",
                confidence_score=0.75,
                impact_potential=0.6,
                implementation_complexity="medium",
                generated_at=datetime.now()
            )
            insights.append(insight)

        return insights

    def identify_error_patterns(self, experiences: List[LearningExperience]) -> List[SystemInsight]:
        """Identify recurring error patterns."""
        insights = []

        # Group errors by type
        error_groups = {}
        for exp in experiences:
            if not exp.outcome.get('success', True):
                error_type = exp.outcome.get('error_type', 'unknown')
                if error_type not in error_groups:
                    error_groups[error_type] = []
                error_groups[error_type].append(exp)

        # Find frequent error patterns
        for error_type, errors in error_groups.items():
            if len(errors) >= 3:  # Recurring pattern
                contexts = [e.context for e in errors]
                common_context = self._find_common_error_context(contexts)

                insight = SystemInsight(
                    insight_id=f"error_pattern_{error_type}_{int(time.time())}",
                    insight_type=InsightType.ERROR_PATTERN,
                    description=f"Recurring error pattern: {error_type}",
                    evidence=[
                        {"error_type": error_type, "occurrences": len(errors)},
                        {"common_context": common_context},
                        {"frequency": len(errors) / len(experiences)}
                    ],
                    recommendation=f"Implement error handling for {error_type} in {common_context}",
                    confidence_score=0.85,
                    impact_potential=0.8,
                    implementation_complexity="low",
                    generated_at=datetime.now()
                )
                insights.append(insight)

        return insights

    def generate_strategy_improvements(self, patterns: List[StrategyPattern]) -> List[SystemInsight]:
        """Generate insights for strategy improvements."""
        insights = []

        # Analyze pattern effectiveness
        for pattern in patterns:
            if pattern.success_rate > 0.8 and pattern.usage_count > 5:
                insight = SystemInsight(
                    insight_id=f"strategy_improve_{pattern.pattern_id}",
                    insight_type=InsightType.STRATEGY_IMPROVEMENT,
                    description=f"High-performing strategy identified: {pattern.description}",
                    evidence=[
                        {"success_rate": pattern.success_rate, "usage_count": pattern.usage_count},
                        {"confidence": pattern.confidence_level}
                    ],
                    recommendation=f"Prioritize strategy '{pattern.description}' in similar contexts",
                    confidence_score=pattern.confidence_level,
                    impact_potential=pattern.success_rate * 0.5,
                    implementation_complexity="low",
                    generated_at=datetime.now()
                )
                insights.append(insight)

        return insights

    def _find_common_error_context(self, contexts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Find common context factors in error scenarios."""
        if not contexts:
            return {}

        # Find most common values across error contexts
        all_keys = set()
        for ctx in contexts:
            all_keys.update(ctx.keys())

        common_factors = {}
        for key in all_keys:
            values = [ctx.get(key) for ctx in contexts if key in ctx]
            if values:
                most_common = max(set(values), key=values.count)
                occurrence_rate = values.count(most_common) / len(values)
                if occurrence_rate > 0.6:  # 60% agreement
                    common_factors[key] = most_common

        return common_factors


class AdaptiveStrategyEngine:
    """Engine for adapting system strategies based on learning."""

    def __init__(self):
        self.current_mode = LearningMode.OBSERVATION
        self.strategy_weights: Dict[str, float] = {}
        self.mode_switch_timer = time.time()
        self.mode_durations = {
            LearningMode.OBSERVATION: 300,      # 5 minutes
            LearningMode.EXPERIMENTATION: 180,  # 3 minutes
            LearningMode.OPTIMIZATION: 120,     # 2 minutes
            LearningMode.ADAPTATION: 60         # 1 minute
        }

    def select_optimal_strategy(self, context: Dict[str, Any],
                               available_strategies: List[str]) -> str:
        """Select the optimal strategy based on current learning state."""
        if not available_strategies:
            return "default"

        # Update learning mode if needed
        self._update_learning_mode()

        if self.current_mode == LearningMode.OBSERVATION:
            # Conservative selection - use proven strategies
            return self._select_conservative_strategy(context, available_strategies)

        elif self.current_mode == LearningMode.EXPERIMENTATION:
            # Experimental selection - try new approaches
            return self._select_experimental_strategy(context, available_strategies)

        elif self.current_mode == LearningMode.OPTIMIZATION:
            # Optimization mode - use best performing strategies
            return self._select_optimized_strategy(context, available_strategies)

        else:  # ADAPTATION
            # Adaptive mode - balance exploration and exploitation
            return self._select_adaptive_strategy(context, available_strategies)

    def _update_learning_mode(self) -> None:
        """Update the current learning mode based on time and conditions."""
        current_time = time.time()
        mode_duration = self.mode_durations[self.current_mode]

        if current_time - self.mode_switch_timer > mode_duration:
            # Cycle through modes
            modes = list(LearningMode)
            current_index = modes.index(self.current_mode)
            next_index = (current_index + 1) % len(modes)
            self.current_mode = modes[next_index]
            self.mode_switch_timer = current_time

            logger.info(f"Meta-learner switched to mode: {self.current_mode.value}")

    def _select_conservative_strategy(self, context: Dict[str, Any],
                                    strategies: List[str]) -> str:
        """Select proven, low-risk strategies."""
        # Prefer strategies with highest historical success rates
        strategy_scores = {}
        for strategy in strategies:
            score = self.strategy_weights.get(strategy, 0.5)  # Default neutral score
            # Add conservatism bias
            score *= 0.9  # Slightly reduce experimental strategies
            strategy_scores[strategy] = score

        return max(strategy_scores.items(), key=lambda x: x[1])[0]

    def _select_experimental_strategy(self, context: Dict[str, Any],
                                    strategies: List[str]) -> str:
        """Select strategies that need more testing."""
        # Favor less-used strategies to gather more data
        strategy_usage = {s: self.strategy_weights.get(f"{s}_usage", 0) for s in strategies}
        min_usage = min(strategy_usage.values())

        # Find strategies with minimal usage
        experimental_strategies = [s for s in strategies if strategy_usage[s] == min_usage]

        if experimental_strategies:
            return random.choice(experimental_strategies)
        else:
            return random.choice(strategies)

    def _select_optimized_strategy(self, context: Dict[str, Any],
                                 strategies: List[str]) -> str:
        """Select highest-performing strategies."""
        return max(strategies, key=lambda s: self.strategy_weights.get(s, 0.5))

    def _select_adaptive_strategy(self, context: Dict[str, Any],
                                strategies: List[str]) -> str:
        """Balance exploration and exploitation."""
        # 70% exploitation, 30% exploration
        if random.random() < 0.7:
            return self._select_optimized_strategy(context, strategies)
        else:
            return self._select_experimental_strategy(context, strategies)

    def update_strategy_weights(self, strategy: str, outcome: Dict[str, Any]) -> None:
        """Update strategy performance weights based on outcomes."""
        success = outcome.get('success', False)
        performance = outcome.get('performance_score', 0.5)

        # Current weight
        current_weight = self.strategy_weights.get(strategy, 0.5)

        # Update with learning rate
        learning_rate = 0.1
        target_weight = performance if success else performance * 0.3

        # Exponential moving average update
        new_weight = current_weight + learning_rate * (target_weight - current_weight)
        self.strategy_weights[strategy] = max(0.0, min(1.0, new_weight))

        # Track usage
        usage_key = f"{strategy}_usage"
        self.strategy_weights[usage_key] = self.strategy_weights.get(usage_key, 0) + 1


class MetaLearnerAgent(BaseAgent):
    """
    Meta-Learner Agent: The autonomous improvement engine of the system.

    This agent continuously learns from system behavior, generates insights,
    adapts strategies, and implements self-improvements to enhance overall
    system performance and intelligence.
    """

    def __init__(
        self,
        agent_id: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None
    ):
        super().__init__(agent_id=agent_id, agent_type="meta_learner", config=config)

        # Core learning components
        self.experience_memory = ExperienceMemory()
        self.insight_generator = InsightGenerator()
        self.adaptive_engine = AdaptiveStrategyEngine()

        # Learning state
        self.learning_cycles_completed = 0
        self.insights_applied = 0
        self.performance_improvements = []
        self.learning_objectives = [
            "improve_system_performance",
            "reduce_error_rates",
            "optimize_resource_usage",
            "enhance_adaptability",
            "increase_prediction_accuracy"
        ]

        self.capabilities = [
            AgentCapability.META_LEARNING,
            AgentCapability.STRATEGY_ADAPTATION,
            AgentCapability.INSIGHT_GENERATION,
            AgentCapability.SELF_IMPROVEMENT,
            AgentCapability.PREDICTIVE_ANALYSIS
        ]

    async def execute(self, task_envelope: TaskEnvelope) -> TaskResultEnvelope:
        """Execute meta-learning tasks."""
        task_data = task_envelope.payload
        operation = task_data.get("operation", "")

        try:
            if operation == "learn_from_experience":
                result = await self._learn_from_experience(task_data)
            elif operation == "generate_insights":
                result = await self._generate_insights(task_data)
            elif operation == "adapt_strategy":
                result = await self._adapt_strategy(task_data)
            elif operation == "analyze_performance":
                result = await self._analyze_performance(task_data)
            elif operation == "predict_optimization":
                result = await self._predict_optimization(task_data)
            else:
                result = {"error": f"Unsupported meta-learning operation: {operation}"}

            return create_task_result_envelope(
                task_id=task_envelope.task_id,
                result=result,
                status="completed"
            )

        except Exception as e:
            logger.error(f"Meta-learning task failed: {e}")
            return create_task_result_envelope(
                task_id=task_envelope.task_id,
                result=None,
                status="failed",
                error=str(e)
            )

    async def _learn_from_experience(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """Learn from a system experience."""
        experience_data = task_data.get("experience", {})

        # Create learning experience
        experience = LearningExperience(
            experience_id=f"exp_{int(time.time())}_{random.randint(1000, 9999)}",
            timestamp=datetime.now(),
            context=experience_data.get("context", {}),
            action_taken=experience_data.get("action", ""),
            outcome=experience_data.get("outcome", {}),
            performance_metrics=experience_data.get("metrics", {}),
            confidence_score=experience_data.get("confidence", 0.5)
        )

        # Add to memory
        self.experience_memory.add_experience(experience)

        # Update strategy weights
        self.adaptive_engine.update_strategy_weights(
            experience.action_taken,
            experience.outcome
        )

        # Extract lessons
        lessons = self._extract_lessons_from_experience(experience)
        experience.lessons_learned = lessons

        # Calculate impact score
        experience.impact_score = self._calculate_experience_impact(experience)

        logger.info(f"Learned from experience: {experience.experience_id} "
                   f"(impact: {experience.impact_score:.2f})")

        return {
            "experience_id": experience.experience_id,
            "lessons_learned": lessons,
            "impact_score": experience.impact_score,
            "memory_size": len(self.experience_memory.experiences)
        }

    async def _generate_insights(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """Generate insights from accumulated experiences."""
        # Extract patterns from experiences
        patterns = self.experience_memory.extract_patterns()

        # Generate different types of insights
        performance_insights = self.insight_generator.analyze_performance_patterns(
            self.experience_memory.experiences
        )

        error_insights = self.insight_generator.identify_error_patterns(
            self.experience_memory.experiences
        )

        strategy_insights = self.insight_generator.generate_strategy_improvements(patterns)

        all_insights = performance_insights + error_insights + strategy_insights

        # Sort by impact potential
        all_insights.sort(key=lambda x: x.impact_potential, reverse=True)

        # Store insights
        self.insight_generator.generated_insights.extend(all_insights)

        logger.info(f"Generated {len(all_insights)} insights "
                   f"({len(patterns)} patterns analyzed)")

        return {
            "insights_generated": len(all_insights),
            "performance_insights": len(performance_insights),
            "error_insights": len(error_insights),
            "strategy_insights": len(strategy_insights),
            "patterns_analyzed": len(patterns),
            "top_insights": [
                {
                    "id": insight.insight_id,
                    "type": insight.insight_type.value,
                    "description": insight.description,
                    "impact": insight.impact_potential,
                    "confidence": insight.confidence_score
                }
                for insight in all_insights[:5]  # Top 5 insights
            ]
        }

    async def _adapt_strategy(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """Adapt system strategy based on learning."""
        context = task_data.get("context", {})
        available_strategies = task_data.get("available_strategies", [])

        if not available_strategies:
            return {"error": "No strategies provided for adaptation"}

        # Select optimal strategy
        optimal_strategy = self.adaptive_engine.select_optimal_strategy(
            context, available_strategies
        )

        # Find similar past experiences
        similar_experiences = self.experience_memory.find_similar_experiences(context)

        # Calculate confidence in selection
        strategy_weight = self.adaptive_engine.strategy_weights.get(optimal_strategy, 0.5)
        experience_count = len(similar_experiences)

        confidence = min(0.95, strategy_weight + (experience_count * 0.05))

        adaptation_result = {
            "selected_strategy": optimal_strategy,
            "learning_mode": self.adaptive_engine.current_mode.value,
            "confidence_score": confidence,
            "similar_experiences": len(similar_experiences),
            "strategy_weights": dict(list(self.adaptive_engine.strategy_weights.items())[:10]),
            "rationale": self._generate_adaptation_rationale(
                optimal_strategy, context, similar_experiences
            )
        }

        logger.info(f"Strategy adaptation: {optimal_strategy} "
                   f"(mode: {self.adaptive_engine.current_mode.value}, "
                   f"confidence: {confidence:.2f})")

        return adaptation_result

    async def _analyze_performance(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze system performance and learning progress."""
        # Calculate learning metrics
        total_experiences = len(self.experience_memory.experiences)
        recent_experiences = [e for e in self.experience_memory.experiences
                            if e.timestamp > datetime.now() - timedelta(hours=1)]

        # Performance trends
        if recent_experiences:
            avg_performance = statistics.mean([
                e.performance_metrics.get('overall_score', 0.5)
                for e in recent_experiences
            ])
            avg_confidence = statistics.mean([e.confidence_score for e in recent_experiences])
        else:
            avg_performance = 0.5
            avg_confidence = 0.5

        # Learning progress
        learning_progress = {
            "total_experiences": total_experiences,
            "recent_experiences": len(recent_experiences),
            "average_performance": avg_performance,
            "average_confidence": avg_confidence,
            "learning_cycles": self.learning_cycles_completed,
            "insights_generated": len(self.insight_generator.generated_insights),
            "insights_applied": self.insights_applied,
            "current_mode": self.adaptive_engine.current_mode.value,
            "strategy_count": len(self.adaptive_engine.strategy_weights),
            "memory_utilization": len(self.experience_memory.experiences) / self.experience_memory.max_experiences
        }

        # Generate improvement recommendations
        recommendations = []
        if avg_performance < 0.7:
            recommendations.append("Consider strategy optimization based on recent performance")
        if avg_confidence < 0.6:
            recommendations.append("Gather more experience data to improve confidence")
        if len(self.insight_generator.generated_insights) > 10:
            recommendations.append("Review and apply generated insights")

        learning_progress["recommendations"] = recommendations

        return learning_progress

    async def _predict_optimization(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """Predict potential optimizations based on learning."""
        context = task_data.get("context", {})

        # Find similar contexts and their outcomes
        similar_experiences = self.experience_memory.find_similar_experiences(context, limit=10)

        if not similar_experiences:
            return {
                "prediction_available": False,
                "reason": "Insufficient similar experiences for prediction"
            }

        # Analyze successful patterns
        successful_experiences = [e for e in similar_experiences if e.outcome.get('success', False)]

        if not successful_experiences:
            return {
                "prediction_available": False,
                "reason": "No successful experiences in similar contexts"
            }

        # Predict optimal actions
        action_counts = {}
        for exp in successful_experiences:
            action = exp.action_taken
            action_counts[action] = action_counts.get(action, 0) + 1

        predicted_action = max(action_counts.items(), key=lambda x: x[1])[0]
        prediction_confidence = action_counts[predicted_action] / len(successful_experiences)

        # Calculate expected performance
        successful_performances = [
            exp.performance_metrics.get('overall_score', 0.5)
            for exp in successful_experiences
            if exp.action_taken == predicted_action
        ]

        expected_performance = statistics.mean(successful_performances) if successful_performances else 0.5

        return {
            "prediction_available": True,
            "predicted_action": predicted_action,
            "confidence": prediction_confidence,
            "expected_performance": expected_performance,
            "similar_experiences": len(similar_experiences),
            "successful_precedents": len(successful_experiences),
            "rationale": f"Based on {len(successful_experiences)} successful experiences "
                        f"in similar contexts, {predicted_action} is predicted to yield "
                        f"{expected_performance:.2f} performance score"
        }

    def _extract_lessons_from_experience(self, experience: LearningExperience) -> List[str]:
        """Extract lessons from a learning experience."""
        lessons = []

        success = experience.outcome.get('success', False)
        performance = experience.performance_metrics.get('overall_score', 0.5)

        if success and performance > 0.8:
            lessons.append("High-performance strategy identified")
        elif success and performance < 0.6:
            lessons.append("Successful but suboptimal performance - room for improvement")
        elif not success:
            error_type = experience.outcome.get('error_type', 'unknown')
            lessons.append(f"Failure pattern identified: {error_type}")

        # Context-specific lessons
        if experience.context.get('load_level') == 'high' and performance < 0.7:
            lessons.append("High load scenarios need optimization")
        elif experience.context.get('resource_constraint') == 'memory' and not success:
            lessons.append("Memory constraints affect reliability")

        return lessons

    def _calculate_experience_impact(self, experience: LearningExperience) -> float:
        """Calculate the impact score of a learning experience."""
        base_impact = 0.5

        # Success/failure impact
        if experience.outcome.get('success', False):
            base_impact += 0.3
        else:
            base_impact -= 0.2

        # Performance impact
        performance = experience.performance_metrics.get('overall_score', 0.5)
        performance_impact = (performance - 0.5) * 0.4  # Scale performance contribution
        base_impact += performance_impact

        # Novelty impact (new strategies get bonus)
        strategy = experience.action_taken
        usage_count = self.adaptive_engine.strategy_weights.get(f"{strategy}_usage", 0)
        if usage_count < 5:  # Relatively new strategy
            base_impact += 0.1

        return max(0.0, min(1.0, base_impact))

    def _generate_adaptation_rationale(self, strategy: str, context: Dict[str, Any],
                                     similar_experiences: List[LearningExperience]) -> str:
        """Generate rationale for strategy selection."""
        if not similar_experiences:
            return f"Selected {strategy} as default strategy (no similar experiences)"

        successful_similar = sum(1 for exp in similar_experiences if exp.outcome.get('success', False))
        success_rate = successful_similar / len(similar_experiences)

        avg_performance = statistics.mean([
            exp.performance_metrics.get('overall_score', 0.5)
            for exp in similar_experiences
        ])

        return (f"Selected {strategy} based on {len(similar_experiences)} similar experiences "
                f"with {success_rate:.1f} success rate and {avg_performance:.2f} average performance")

    async def run_learning_cycle(self) -> Dict[str, Any]:
        """Run a complete learning cycle."""
        cycle_start = time.time()

        # Phase 1: Experience analysis
        await self._analyze_recent_experiences()

        # Phase 2: Insight generation
        insights_result = await self._generate_insights({})

        # Phase 3: Strategy adaptation
        await self._update_strategy_weights()

        # Phase 4: Learning evaluation
        evaluation = await self._evaluate_learning_progress()

        cycle_duration = time.time() - cycle_start
        self.learning_cycles_completed += 1

        cycle_result = {
            "cycle_number": self.learning_cycles_completed,
            "duration": cycle_duration,
            "insights_generated": insights_result.get("insights_generated", 0),
            "evaluation": evaluation,
            "learning_mode": self.adaptive_engine.current_mode.value
        }

        logger.info(f"Learning cycle {self.learning_cycles_completed} completed "
                   f"({cycle_duration:.2f}s, {insights_result.get('insights_generated', 0)} insights)")

        return cycle_result

    async def _analyze_recent_experiences(self) -> None:
        """Analyze recent experiences for patterns."""
        recent_experiences = [
            exp for exp in self.experience_memory.experiences
            if exp.timestamp > datetime.now() - timedelta(minutes=30)
        ]

        if len(recent_experiences) >= 3:
            # Extract and store patterns
            patterns = self.experience_memory.extract_patterns()
            logger.debug(f"Extracted {len(patterns)} patterns from {len(recent_experiences)} experiences")

    async def _update_strategy_weights(self) -> None:
        """Update strategy weights based on recent performance."""
        # This is handled incrementally in update_strategy_weights, but we can
        # add batch updates here if needed
        pass

    async def _evaluate_learning_progress(self) -> Dict[str, Any]:
        """Evaluate overall learning progress."""
        total_experiences = len(self.experience_memory.experiences)
        successful_experiences = sum(
            1 for exp in self.experience_memory.experiences
            if exp.outcome.get('success', False)
        )

        success_rate = successful_experiences / total_experiences if total_experiences > 0 else 0

        recent_experiences = [
            exp for exp in self.experience_memory.experiences
            if exp.timestamp > datetime.now() - timedelta(hours=1)
        ]

        if recent_experiences:
            recent_success_rate = sum(
                1 for exp in recent_experiences
                if exp.outcome.get('success', False)
            ) / len(recent_experiences)
        else:
            recent_success_rate = 0

        return {
            "overall_success_rate": success_rate,
            "recent_success_rate": recent_success_rate,
            "total_experiences": total_experiences,
            "learning_efficiency": recent_success_rate - success_rate,  # Improvement trend
            "insights_applied": self.insights_applied,
            "active_strategies": len(self.adaptive_engine.strategy_weights)
        }
